{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HaRe\n",
    "====\n",
    "\n",
    "HaRe (Harassment Recognizer) is a command line tool and Python library to automatically detect harassment as it happens (real-time) with the help of machine learning techniques. In this notebook we will look at the Python library.\n",
    "\n",
    "Basic usage: monitoring conversations\n",
    "--------------------------------------------------------\n",
    "\n",
    "The easiest way to use HaRe is by simply loading a pretrained HaRe model included with this repo in the models folder, like the one named 'simple':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hare import load_pretrained\n",
    "\n",
    "moba_hare = load_pretrained('hare/pretrained/simple')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can then use this object to monitor conversations in progress. Let's start a conversation and ask HaRe to monitor it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hare import Conversation\n",
    "\n",
    "convo = Conversation()\n",
    "moba_hare.add_conversation(convo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At any point in time, you can then request the current status of the conversation according to this HaRe model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 0.8264739513397217, 'b': 0.8264739513397217}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.add_utterance(speaker='a',content='hello')\n",
    "convo.add_utterance(speaker='b',content='hi everyone')\n",
    "moba_hare.get_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also add multiple sentences at once (for example a whole conversation if it has already finished), and see what HaRe's best guess was at every moment in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: hello\n",
      "{'a': 0.8264739513397217}\n",
      "---\n",
      "\n",
      "b: hi everyone\n",
      "{'a': 0.8264739513397217, 'b': 0.8264739513397217}\n",
      "---\n",
      "\n",
      "a: good luck\n",
      "{'a': 0.8264739513397217, 'b': 0.8264739513397217}\n",
      "---\n",
      "\n",
      "c: ur all n00bs\n",
      "{'a': 0.8264739513397217, 'b': 0.8264739513397217, 'c': 0.8264739513397217}\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from hare import Utterance\n",
    "\n",
    "convo.add_utterances([Utterance(speaker='a',content='good luck'),\n",
    "                          Utterance(speaker='c',content='ur all n00bs')])\n",
    "\n",
    "moba_hare.visualize_history_for_conversation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or in a graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from hare.visualize import visualize_toxicity_for_one_conversation\n",
    "    \n",
    "visualize_toxicity_for_one_conversation(moba_hare)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you add multiple conversations for Hare to monitor, you will need to specify the conversation index when asking for the status:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 0.8264739513397217, 'b': 0.8264739513397217}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_convo = Conversation()\n",
    "\n",
    "second_convo.add_utterance(speaker='a',content='hello')\n",
    "second_convo.add_utterance(speaker='b',content='hi everyone')\n",
    "second_convo.add_utterance(speaker='a',content='go away loser!')\n",
    "\n",
    "moba_hare.add_conversation(second_convo)\n",
    "moba_hare.get_status(id=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating \n",
    "----------\n",
    "If you have a labeled dataset (that is: for each conversation an indication which participants are considered toxic), HaRe can calculate to what extent its judgments match the labels. A label can range from the default 0 (not toxic at all) to 1 (maximally toxic). Let's label speaker c:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo.label_speaker('c',1)\n",
    "second_convo.label_speaker('a',0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several evaluation metrics, depending on what is important to you (detecting ALL harassment, detecting harassment quickly, no false positives, etc). You can ask the HaRe object to output these aggregate scores directly, but we can also visualize them similar to how we visualized the estimates for a single conversation. \n",
    "\n",
    "Below we load in 10 labeled example conversations, and visualize three evaluation metrics indicating how well this HaRe object performs on this small dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "[0.9642857142857143, 0.8571428571428571, 0.7678571428571429, 0.7142857142857143, 0.6785714285714286, 0.6785714285714286, 0.6428571428571429, 0.6071428571428571, 0.5714285714285714, 0.5714285714285714, 0.5714285714285714, 0.5714285714285714, 0.5357142857142857, 0.5178571428571429, 0.5, 0.48214285714285715, 0.4642857142857143, 0.4642857142857143, 0.44642857142857145, 0.46153846153846156, 0.46153846153846156, 0.46153846153846156, 0.4423076923076923, 0.46153846153846156, 0.46153846153846156, 0.46153846153846156, 0.46153846153846156, 0.4230769230769231, 0.4230769230769231, 0.40384615384615385, 0.38461538461538464, 0.38461538461538464, 0.38461538461538464, 0.38461538461538464, 0.38461538461538464, 0.36538461538461536, 0.34615384615384615, 0.35555555555555557, 0.3888888888888889, 0.3888888888888889, 0.3888888888888889, 0.3888888888888889, 0.3888888888888889, 0.5, 0.5, 0.4642857142857143, 0.4642857142857143, 0.4642857142857143, 0.4642857142857143, 0.5, 0.5, 0.5, 0.5714285714285714, 0.5714285714285714, 0.5714285714285714, 0.5714285714285714, 0.5714285714285714, 0.5714285714285714, 0.5714285714285714, 0.5714285714285714, 0.5714285714285714, 0.5714285714285714, 0.5714285714285714, 0.5714285714285714, 0.5714285714285714, 0.5714285714285714, 0.5714285714285714, 0.5714285714285714, 0.5714285714285714, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "[0.9270833333333334, 0.8658854166666666, 0.8046875, 0.7643229166666667, 0.7343750000000001, 0.7304687500000001, 0.74609375, 0.7174479166666667, 0.6705729166666666, 0.6510416666666666, 0.6510416666666666, 0.6393229166666666, 0.5950520833333334, 0.5729166666666667, 0.55078125, 0.5364583333333333, 0.5182291666666667, 0.515625, 0.4869791666666667, 0.473015873015873, 0.473015873015873, 0.46349206349206346, 0.4444444444444444, 0.4476190476190476, 0.4476190476190476, 0.4476190476190476, 0.4476190476190476, 0.4095238095238095, 0.4095238095238095, 0.3904761904761904, 0.346031746031746, 0.346031746031746, 0.346031746031746, 0.346031746031746, 0.346031746031746, 0.32539682539682535, 0.3047619047619048, 0.2863247863247863, 0.2903225806451613, 0.2903225806451613, 0.2903225806451613, 0.2903225806451613, 0.2903225806451613, 0.38020833333333337, 0.38020833333333337, 0.3125, 0.3125, 0.3125, 0.3125, 0.1764705882352941, 0.1764705882352941, 0.1764705882352941, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Hare' object has no attribute 'calculate_fscore_at_utterance'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-f4c1cbf5c6bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mvisualize_accuracy_during_conversations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmoba_hare\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mvisualize_auc_during_conversations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmoba_hare\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mvisualize_fscore_during_conversations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmoba_hare\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/vol/tensusers2/wstoop/HaRe/hare/visualize.py\u001b[0m in \u001b[0;36mvisualize_fscore_during_conversations\u001b[0;34m(hare_obj)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvisualize_fscore_during_conversations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhare_obj\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mHare\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m     \u001b[0maccuracies\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_metric_during_conversations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhare_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'fscore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/vol/tensusers2/wstoop/HaRe/hare/visualize.py\u001b[0m in \u001b[0;36mget_metric_during_conversations\u001b[0;34m(hare_obj, metric_name)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mutterance_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength_of_longest_conversation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhare_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'calculate_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmetric_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_at_utterance'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutterance_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Hare' object has no attribute 'calculate_fscore_at_utterance'"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "from hare import load_pretrained, load_example_conversations\n",
    "from hare.visualize import visualize_accuracy_during_conversations, visualize_auc_during_conversations, visualize_fscore_during_conversations\n",
    "\n",
    "moba_hare = load_pretrained('hare/pretrained/simple')\n",
    "for conversation in load_example_conversations():\n",
    "    moba_hare.add_conversation(conversation)\n",
    "    \n",
    "visualize_accuracy_during_conversations(moba_hare)\n",
    "visualize_auc_during_conversations(moba_hare)\n",
    "visualize_fscore_during_conversations(moba_hare)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expect, we see that the estimates are poor in the beginning of conversations, when there is almost no information, and that this gradually gets better as more people speak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for utterance_index in [0,1,2]:\n",
    "    print('Accuracy of this HaRe at utterance',utterance_index,moba_hare.calculate_accuracy_at_utterance(utterance_index))\n",
    "    \n",
    "for utterance_index in [0,1,2]:\n",
    "    print('AUC of this HaRe at utterance',utterance_index,moba_hare.calculate_auc_at_utterance(utterance_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training\n",
    "======="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the existing pretrained models do not score high enough on your conversations, you can use train your own models. Before you cand do this, you need to select a 'brain', which is the classification algorithm HaRe will use under the hood. At the moment, neural networks with Bidirectional Gated Recurrent Units are popular for text classification, so we will use the `BiGruBrain`. This 'brain' uses the implementation in TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hare import Hare, BiGruBrain\n",
    "\n",
    "custom_hare = Hare()\n",
    "custom_hare.brain = BiGruBrain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An interesting option for BiGruBrains (and potentially others) is that they allow you to add word embeddings, which you can see as general knowledge on the meaning of words, collected from large amounts of texts (like Wikipedia)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_hare.brain.embedding_location = '/vol/bigdata/word_embeddings/glove/glove.6B.50d.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, all we need to do is add the conversation we want to train on, and we're ready to start training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_hare.add_conversation(convo)\n",
    "custom_hare.add_conversation(second_convo)\n",
    "\n",
    "custom_hare.train()\n",
    "custom_hare.save('name_of_folder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
