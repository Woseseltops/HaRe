{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HaRe\n",
    "====\n",
    "\n",
    "HaRe (Harassment Recognizer) is a command line tool and Python library to automatically detect harassment as it happens (real-time) with the help of machine learning techniques. In this notebook we will look at the Python library.\n",
    "\n",
    "Basic usage: monitoring conversations\n",
    "--------------------------------------------------------\n",
    "\n",
    "The easiest way to use HaRe is by simply loading a pretrained HaRe model included with this repo in the models folder, like the one named 'simple':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hare import load_pretrained\n",
    "\n",
    "moba_hare = load_pretrained('hare/pretrained/moba')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can then use this object to monitor conversations in progress. Let's start a conversation and ask HaRe to monitor it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hare import Conversation\n",
    "\n",
    "convo = Conversation()\n",
    "moba_hare.add_conversation(convo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At any point in time, you can then request the current status of the conversation according to this HaRe model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 0.20558249950408936, 'b': 0.16650508344173431}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.add_utterance(speaker='a',content='hello')\n",
    "convo.add_utterance(speaker='b',content='hi everyone')\n",
    "moba_hare.get_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also add multiple sentences at once (for example a whole conversation if it has already finished), and see what HaRe's best guess was at every moment in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: hello\n",
      "{'a': 0.20558249950408936}\n",
      "---\n",
      "\n",
      "b: hi everyone\n",
      "{'a': 0.20558249950408936, 'b': 0.16650508344173431}\n",
      "---\n",
      "\n",
      "a: good luck\n",
      "{'a': 0.20558249950408936, 'b': 0.16650508344173431}\n",
      "---\n",
      "\n",
      "c: ur all n00bs\n",
      "{'a': 0.20558249950408936, 'b': 0.16650508344173431, 'c': 0.2093217968940735}\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from hare import Utterance\n",
    "\n",
    "convo.add_utterances([Utterance(speaker='a',content='good luck'),\n",
    "                          Utterance(speaker='c',content='ur all n00bs')])\n",
    "\n",
    "moba_hare.visualize_history_for_conversation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you add multiple conversations for Hare to monitor, you will need to specify the conversation index when asking for the status:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 0.20558249950408936, 'b': 0.16650508344173431}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_convo = Conversation()\n",
    "\n",
    "second_convo.add_utterance(speaker='a',content='hello')\n",
    "second_convo.add_utterance(speaker='b',content='hi everyone')\n",
    "\n",
    "moba_hare.add_conversation(second_convo)\n",
    "moba_hare.get_status(id=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating \n",
    "----------\n",
    "If you have a labeled dataset (that is: for each conversation an indication which participants are considered toxic), HaRe can calculate to what extent its judgments match the labels. A label can range from the default 0 (not toxic at all) to 1 (maximally toxic). Let's label speaker c:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo.label_speaker('c',0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several evaluation metrics, depending on what is important to you (detecting ALL harassment, detecting harassment quickly, no false positives, etc):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moba_hare.calculate_retrospective_accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training\n",
    "======="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the existing pretrained models do not score high enough on your conversations, you can use train your own models. Before you cand do this, you need to select a 'brain', which is the classification algorithm HaRe will use under the hood. At the moment, neural networks with Bidirectional Gated Recurrent Units are popular for text classification, so we will use the `BiGruBrain`. This 'brain' uses the implementation in TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hare import Hare, BiGruBrain\n",
    "\n",
    "custom_hare = Hare()\n",
    "custom_hare.brain = BiGruBrain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An interesting option for BiGruBrains (and potentially others) is that they allow you to add word embeddings, which you can see as general knowledge on the meaning of words, collected from large amounts of texts (like Wikipedia)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_hare.brain.embedding_location = '/vol/bigdata/word_embeddings/glove/glove.6B.50d.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, all we need to do is add the conversation we want to train on, and we're ready to start training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5/5 [==============================] - 2s 437ms/step - loss: 0.7099 - acc: 0.0000e+00\n",
      "Epoch 2/3\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6164 - acc: 0.8000\n",
      "Epoch 3/3\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.5157 - acc: 0.8000\n"
     ]
    }
   ],
   "source": [
    "custom_hare.add_conversation(convo)\n",
    "custom_hare.add_conversation(second_convo)\n",
    "\n",
    "custom_hare.train()\n",
    "custom_hare.save('name_of_folder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
