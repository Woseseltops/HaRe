TODO
====
Interactive article:
1. Implement interactive visualization to evaluate classifiers during conversations
   * Start with the graphs, hardcoding the source files
     * Have the data from the source files shown in the graphs as you click through the settings
       * Set a max y in the graph code
     * Create data json files for dict and bigru, all settings
       * Remove later players
2. Show the difference between dict and BiGru
3. Use this visualization to figure out
   * If we can do without Bi
   * If we can get a comparable score WITH word embeddings
     * If the neuron visualizations for word embeddings are more organized

Code
* Fix type hinting
* Visualize module: too much duplicate code
* Add save option for all visualization functions

Ideas to make the model better
==============================
Use toxic embeddings (make sure to not mix up train and test data!)
Separate casing
Do sequences really need to have a fixed length?

Backlog
=======
* Experiment with neural nets:
  * Study best model in Kaggle... what is different from this experiment? https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/discussion/52557
    * Check: how is it possible that with less data, scores are higher?
    * Combine embeddings

  * See if this best result can be improved by using Ulmfit http://nlp.fast.ai/ or Bert https://towardsdatascience.com/bert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270
    * https://www.analyticsvidhya.com/blog/2018/11/tutorial-text-classification-ulmfit-fastai-library/

* Look up: what exactly is ConvoKit?